# ============================================
# REQUIRED environment variables
# ============================================
# These must be filled in for the bot to work

# Telegram Bot Token (get from @BotFather)
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# API key for LLM (OpenAI, Fireworks, OpenRouter, etc.)
OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# OPTIONAL environment variables (with defaults)
# ============================================
# These have default values and can be left as-is or customized

# Base URL for API (Fireworks, OpenAI, OpenRouter, etc.)
# Default: https://api.fireworks.ai/inference/v1
OPENAI_BASE_URL=https://api.fireworks.ai/inference/v1

# Model for answer generation
# Default: accounts/fireworks/models/llama-v3p1-8b-instruct
LLM_MODEL=accounts/fireworks/models/llama-v3p1-8b-instruct

# Embeddings model
# Default: accounts/fireworks/models/nomic-embed-text-v1
# Popular models:
#   OpenAI/Fireworks: accounts/fireworks/models/nomic-embed-text-v1
#   HuggingFace (multilingual): sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
#   HuggingFace (Russian): cointegrated/rubert-tiny2, ai-forever/sbert_large_nlu_ru
#   HuggingFace (high quality): intfloat/multilingual-e5-base, intfloat/multilingual-e5-large
#   Ollama: nomic-embed-text
EMBEDDINGS_MODEL=accounts/fireworks/models/nomic-embed-text-v1

# Embeddings provider for main system (openai/huggingface/ollama)
# Default: ollama
# openai - uses OpenAI/Fireworks API (requires API key, paid)
# huggingface - uses local HuggingFace models (free, runs locally, requires internet for first download)
# ollama - uses Ollama (requires local Ollama server, free)
EMBEDDINGS_PROVIDER=ollama

# System role for the bot
# Default: банковский ассистент
SYSTEM_ROLE=банковский ассистент

# Number of recent turns for context
# Default: 8
CONTEXT_TURNS=8

# Number of chunks to retrieve (top-K)
# Default: 4
RETRIEVER_K=4

# Path to data directory (PDF and JSON files)
# Default: @data
DATA_PATH=@data

# Logging level (DEBUG, INFO, WARNING, ERROR)
# Default: INFO
LOG_LEVEL=INFO

# Show sources in answer (true/false)
# Default: false
SHOW_SOURCES=false

# ============================================
# LangSmith settings (optional)
# ============================================

# LangSmith API key (get from smith.langchain.com)
# Starts with lsv2_pt_...
# Automatically enables tracing of all RAG pipeline requests when present
LANGSMITH_API_KEY=your_langsmith_api_key_here

# Project name in LangSmith (optional)
LANGSMITH_PROJECT=06-monitoring-qa

# ============================================
# RAGAS settings (optional, for evaluation)
# ============================================

# Model for RAGAS metrics (default: LLM_MODEL)
RAGAS_LLM_MODEL=

# Embeddings model for RAGAS (default: EMBEDDINGS_MODEL)
# Leave empty to use EMBEDDINGS_MODEL
# Popular HuggingFace models for RAGAS:
#   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (fast, good quality)
#   intfloat/multilingual-e5-base (better quality, slower)
#   cointegrated/rubert-tiny2 (Russian, very fast)
RAGAS_EMBEDDING_MODEL=

# Embeddings provider for RAGAS (openai/huggingface)
# Default: "openai"
# For free usage, you can use "huggingface" with local models
# Note: RAGAS evaluation requires embeddings, so set this to match your setup
RAGAS_EMBEDDINGS_PROVIDER=openai

# ============================================
# HuggingFace settings (optional, for local models)
# ============================================

# Device for HuggingFace models (cpu/cuda)
# Default: cpu
# Use "cuda" if you have GPU available and want to use it
HUGGINGFACE_DEVICE=cpu

# Cache folder for HuggingFace models (optional)
# Default: None (uses default HuggingFace cache)
# Example: ./models/cache
HUGGINGFACE_CACHE_FOLDER=

# Normalize embeddings for HuggingFace (true/false)
# Default: true
# Normalizing embeddings improves cosine similarity calculations
# Recommended: true for most use cases
HUGGINGFACE_NORMALIZE_EMBEDDINGS=true

# ============================================
# Example configurations for different scenarios
# ============================================
# Uncomment and modify one of the following configurations based on your needs

# === Configuration 1: OpenAI/Fireworks API (requires API key) ===
# EMBEDDINGS_PROVIDER=openai
# EMBEDDINGS_MODEL=accounts/fireworks/models/nomic-embed-text-v1
# RAGAS_EMBEDDINGS_PROVIDER=openai
# RAGAS_EMBEDDING_MODEL=accounts/fireworks/models/nomic-embed-text-v1

# === Configuration 2: HuggingFace (free, local models) ===
# EMBEDDINGS_PROVIDER=huggingface
# EMBEDDINGS_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# RAGAS_EMBEDDINGS_PROVIDER=huggingface
# RAGAS_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# HUGGINGFACE_DEVICE=cpu
# HUGGINGFACE_NORMALIZE_EMBEDDINGS=true

# === Configuration 3: HuggingFace with Russian model (best for Russian language) ===
# EMBEDDINGS_PROVIDER=huggingface
# EMBEDDINGS_MODEL=cointegrated/rubert-tiny2
# RAGAS_EMBEDDINGS_PROVIDER=huggingface
# RAGAS_EMBEDDING_MODEL=cointegrated/rubert-tiny2
# HUGGINGFACE_DEVICE=cpu
# HUGGINGFACE_NORMALIZE_EMBEDDINGS=true

# === Configuration 4: HuggingFace with high-quality model (slower but better) ===
# EMBEDDINGS_PROVIDER=huggingface
# EMBEDDINGS_MODEL=intfloat/multilingual-e5-base
# RAGAS_EMBEDDINGS_PROVIDER=huggingface
# RAGAS_EMBEDDING_MODEL=intfloat/multilingual-e5-base
# HUGGINGFACE_DEVICE=cpu
# HUGGINGFACE_NORMALIZE_EMBEDDINGS=true

# === Configuration 5: Ollama (requires local Ollama server) ===
# EMBEDDINGS_PROVIDER=ollama
# EMBEDDINGS_MODEL=nomic-embed-text
# RAGAS_EMBEDDINGS_PROVIDER=openai  # Note: Ollama not supported for RAGAS, use OpenAI/HuggingFace
# RAGAS_EMBEDDING_MODEL=accounts/fireworks/models/nomic-embed-text-v1

# === Configuration 6: Mixed (Ollama for main, HuggingFace for RAGAS) ===
# EMBEDDINGS_PROVIDER=ollama
# EMBEDDINGS_MODEL=nomic-embed-text
# RAGAS_EMBEDDINGS_PROVIDER=huggingface
# RAGAS_EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# HUGGINGFACE_DEVICE=cpu
# HUGGINGFACE_NORMALIZE_EMBEDDINGS=true