# src/app/bot/handlers.py
import asyncio
import logging
from typing import List

from aiogram import Router, types
from aiogram.filters import Command
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage
from openai import BadRequestError

from indexer_with_json import reindex_all
from src.app import config
from src.app.evaluation.evaluation import (
    evaluate_rag_pipeline_with_feedback,
    _load_dataset_from_langsmith,
    _run_rag_on_dataset,
)
from src.app.indexing import describe_index_status, run_full_indexing
from src.app.indexing.vector_store import get_vector_store_manager
from src.app.memory.session import SessionManager
from src.app.rag.chain import build_rag_chain
from src.app.synthesis.dataset_synthesizer import synthesize_dataset

logger = logging.getLogger(__name__)
router = Router()

session_manager = SessionManager()


@router.message(Command("start"))
async def command_start_handler(message: types.Message) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /start."""
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /start –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %s", user_id)

    session_manager.clear_session(user_id)

    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–∞–Ω–∫–æ–≤—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã, –∏ —è –ø–æ–º–æ–≥—É –≤–∞–º."
    )


@router.message(Command("help"))
async def command_help_handler(message: types.Message) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /help."""
    user_id = message.from_user.id if message.from_user else "unknown"
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /help –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %s", user_id)
    help_text = (
        "–Ø –±–∞–Ω–∫–æ–≤—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã, –∏ —è –æ—Ç–≤–µ—á—É –Ω–∞ –Ω–∏—Ö.\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/start - –ù–∞—á–∞—Ç—å –¥–∏–∞–ª–æ–≥\n"
        "/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É\n"
        "/reset - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞\n"
        "/index - –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã\n"
        "/index_status - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏\n"
    )
    if config.LANGSMITH_API_KEY:
        help_text += "/synthesize_dataset - –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
        help_text += "/evaluate_dataset - –ó–∞–ø—É—Å—Ç–∏—Ç—å evaluation –∫–∞—á–µ—Å—Ç–≤–∞ RAG pipeline\n"
    await message.answer(help_text)


@router.message(Command("reset"))
async def command_reset_handler(message: types.Message) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /reset."""
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /reset –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s. –û—á–∏—Å—Ç–∫–∞ —Å–µ—Å—Å–∏–∏.", user_id)
    session_manager.clear_session(user_id)
    await message.answer("–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞. –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.")


@router.message(Command("index"))
async def command_index_handler(message: types.Message) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö."""
    user_id = message.from_user.id if message.from_user else -1
    manager = get_vector_store_manager()
    status = manager.status.state

    if status == "running":
        logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –∑–∞–ø—Ä–æ—Å–∏–ª /index, –Ω–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–∂–µ –∏–¥—ë—Ç.", user_id)
        await message.answer("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å –ø–æ–∑–∂–µ –∫–æ–º–∞–Ω–¥–æ–π /index_status.")
        return

    logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s.", user_id)
    await message.answer("–ó–∞–ø—É—Å–∫–∞—é –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ /index_status.")
    asyncio.create_task(run_full_indexing())


@router.message(Command("index_status"))
async def command_index_status_handler(message: types.Message) -> None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Ç–µ–∫—É—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞."""
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –∑–∞–ø—Ä–æ—Å–∏–ª /index_status.", user_id)
    status_message = describe_index_status()
    await message.answer(status_message)


@router.message(Command("synthesize_dataset"))
async def command_synthesize_dataset_handler(message: types.Message) -> None:
    """–°–æ–∑–¥–∞—ë—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è evaluation."""
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /synthesize_dataset –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s.", user_id)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ LangSmith API –∫–ª—é—á–∞
    if not config.LANGSMITH_API_KEY:
        await message.answer(
            "‚ùå LangSmith API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. "
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è LANGSMITH_API_KEY –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞."
        )
        return

    # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    dataset_name = config.LANGSMITH_PROJECT or "06-rag-qa-dataset"

    await message.answer(
        f"üîÑ –ù–∞—á–∏–Ω–∞—é —Å–∏–Ω—Ç–µ–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ '{dataset_name}' –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. "
        "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
    )

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ç–µ–∑ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        def run_synthesis():
            return synthesize_dataset(
                dataset_name=dataset_name,
                upload_to_langsmith=True,
            )

        saved_path = await asyncio.to_thread(run_synthesis)

        await message.answer(
            f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ LangSmith!\n\n"
            f"–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {saved_path}\n\n"
            "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å evaluation –∫–æ–º–∞–Ω–¥–æ–π /evaluate_dataset"
        )
        logger.info("–°–∏–Ω—Ç–µ–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à—ë–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s. –§–∞–π–ª: %s", user_id, saved_path)

    except Exception as exc:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ç–µ–∑–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, exc)
        await message.answer(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {exc}\n"
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )


@router.message(Command("debug_eval_examples"))
async def command_debug_eval_examples_handler(message: types.Message) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ evaluation: –≤–æ–ø—Ä–æ—Å, —ç—Ç–∞–ª–æ–Ω, –æ—Ç–≤–µ—Ç RAG –∏ –ø–µ—Ä–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.

    –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ in-memory –∏–Ω–¥–µ–∫—Å –∏ retriever, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –±–æ—Ç,
    –ø–æ—ç—Ç–æ–º—É –∫–æ–º–∞–Ω–¥—É –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –≤—ã–∑—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ /index.
    """
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /debug_eval_examples –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s.", user_id)

    if not config.LANGSMITH_API_KEY:
        await message.answer(
            "‚ùå LangSmith API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. "
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è LANGSMITH_API_KEY, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç."
        )
        return

    manager = get_vector_store_manager()
    status = manager.status
    if status.chunks == 0:
        await message.answer(
            "‚ùå –ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç. –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ evaluation –Ω—É–∂–µ–Ω –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n\n"
            "–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ /index –∏ –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –∑–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É."
        )
        return

    dataset_name = config.LANGSMITH_PROJECT or "06-monitoring-qa"
    await message.answer(
        f"üîç –ó–∞–≥—Ä—É–∂–∞—é –¥–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –∏ –ø—Ä–æ–≥–æ–Ω—è—é –ø–µ—Ä–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã —á–µ—Ä–µ–∑ RAG..."
    )

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –±–µ—Ä—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        dataset = _load_dataset_from_langsmith(dataset_name)
        if dataset is None or len(dataset) == 0:
            await message.answer(
                f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –∏–∑ LangSmith "
                "–∏–ª–∏ –æ–Ω –ø—É—Å—Ç."
            )
            return

        examples_to_show = min(3, len(dataset))
        subset = dataset.select(range(examples_to_show))

        retriever = manager.get_retriever()

        # _run_rag_on_dataset –≤–Ω—É—Ç—Ä–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç asyncio.run, –ø–æ—ç—Ç–æ–º—É –∑–∞–ø—É—Å–∫–∞–µ–º –µ–≥–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        dataset_with_rag = await asyncio.to_thread(
            _run_rag_on_dataset,
            subset,
            retriever,
        )

        lines: list[str] = []
        for idx in range(examples_to_show):
            ex = dataset_with_rag[idx]
            question = ex.get("question", "")
            ground_truths = ex.get("ground_truths") or [""]
            ground_truth = ground_truths[0] if ground_truths else ""
            answer = ex.get("answer", "")
            contexts = ex.get("contexts") or []
            first_context = contexts[0] if contexts else ""

            def _short(text: str, limit: int = 300) -> str:
                text = (text or "").replace("\n", " ")
                return text[:limit] + ("..." if len(text) > limit else "")

            lines.append(
                f"=== –ü—Ä–∏–º–µ—Ä {idx + 1} ===\n"
                f"‚ùì –í–æ–ø—Ä–æ—Å: {_short(question)}\n"
                f"‚úÖ –≠—Ç–∞–ª–æ–Ω: {_short(ground_truth)}\n"
                f"ü§ñ –û—Ç–≤–µ—Ç RAG: {_short(answer)}\n"
                f"üìö –ü–µ—Ä–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {_short(first_context) if first_context else '<–Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞>'}\n"
            )

        text = "–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –æ—Ç–≤–µ—Ç—ã —Ç–µ–∫—É—â–µ–≥–æ RAG:\n\n" + "\n".join(lines)
        await message.answer(text)
        logger.info(
            "–û—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã debug-–ø—Ä–∏–º–µ—Ä—ã evaluation –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é %s (dataset=%s, examples=%s).",
            user_id,
            dataset_name,
            examples_to_show,
        )
    except Exception as exc:
        logger.exception("–û—à–∏–±–∫–∞ –≤ /debug_eval_examples –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, exc)
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ evaluation. "
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π."
        )


@router.message(Command("evaluate_dataset"))
async def command_evaluate_dataset_handler(message: types.Message) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç evaluation RAG pipeline —á–µ—Ä–µ–∑ RAGAS –º–µ—Ç—Ä–∏–∫–∏."""
    user_id = message.from_user.id if message.from_user else -1
    logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /evaluate_dataset –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s.", user_id)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ LangSmith API –∫–ª—é—á–∞
    if not config.LANGSMITH_API_KEY:
        await message.answer(
            "‚ùå LangSmith API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. "
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è LANGSMITH_API_KEY –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è evaluation."
        )
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    # –ò–Ω–¥–µ–∫—Å –Ω—É–∂–µ–Ω –¥–ª—è RAG pipeline: evaluation –∑–∞–ø—É—Å–∫–∞–µ—Ç RAG –Ω–∞ –∫–∞–∂–¥–æ–º –≤–æ–ø—Ä–æ—Å–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞,
    # –∏ RAG –∏—Å–ø–æ–ª—å–∑—É–µ—Ç retriever –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ
    manager = get_vector_store_manager()
    status = manager.status

    if status.chunks == 0:
        await message.answer(
            "‚ùå –ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç. –î–ª—è evaluation –Ω—É–∂–µ–Ω –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n\n"
            "Evaluation –∑–∞–ø—É—Å–∫–∞–µ—Ç RAG pipeline –Ω–∞ –∫–∞–∂–¥–æ–º –≤–æ–ø—Ä–æ—Å–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞:\n"
            "1. –í–æ–ø—Ä–æ—Å –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n"
            "2. RAG –∏—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∏–Ω–¥–µ–∫—Å–µ\n"
            "3. RAG –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
            "4. RAGAS –≤—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤\n\n"
            "–ó–∞–ø—É—Å—Ç–∏—Ç–µ /index –∏ –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –∑–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É."
        )
        return

    # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    dataset_name = config.LANGSMITH_PROJECT or "06-rag-qa-dataset"

    await message.answer(
        f"üîÑ –ó–∞–ø—É—Å–∫–∞—é evaluation –¥–∞—Ç–∞—Å–µ—Ç–∞ '{dataset_name}'. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
    )

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º evaluation –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        retriever = manager.get_retriever()
        result = await asyncio.to_thread(
            evaluate_rag_pipeline_with_feedback,
            dataset_name=dataset_name,
            retriever=retriever,
            upload_feedback=True,
        )
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º –º–µ—Ç—Ä–∏–∫ –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂–µ–º (–º–µ—Ç—Ä–∏–∫–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤)
        if isinstance(result, tuple):
            metrics, examples_count = result
        else:
            metrics = result
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
            try:
                from langsmith import Client
                client = Client(api_key=config.LANGSMITH_API_KEY)
                dataset_info = client.read_dataset(dataset_name=dataset_name)
                examples_count = dataset_info.example_count if hasattr(dataset_info, 'example_count') else len(metrics.get('faithfulness', [])) if isinstance(metrics.get('faithfulness'), list) else '?'
            except Exception:
                examples_count = len(metrics.get('faithfulness', [])) if isinstance(metrics.get('faithfulness'), list) else '?'

        # –°–ª–æ–≤–∞—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Ç—Ä–∏–∫ —Ä—É—Å—Å–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è–º –∏ —Ü–≤–µ—Ç–∞–º
        metric_translations = {
            "faithfulness": ("–û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–Ω–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)", "üü¢"),
            "answer_relevancy": ("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞", "üü°"),
            "answer_correctness": ("–ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞", "üü¢"),
            "answer_similarity": ("–ü–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ —ç—Ç–∞–ª–æ–Ω", "üü¢"),
            "context_recall": ("–ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", "üü°"),
            "context_precision": ("–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞", "üü¢"),
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –∫—Ä—É–∂–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏
        def get_metric_emoji(metric_name: str, value: float) -> str:
            """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–æ–¥–∑–∏ –∫—Ä—É–∂–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏."""
            # –î–ª—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞: –∑–µ–ª–µ–Ω—ã–π > 0.7, –∂–µ–ª—Ç—ã–π 0.5-0.7, –∫—Ä–∞—Å–Ω—ã–π < 0.5
            if value >= 0.7:
                return "üü¢"
            elif value >= 0.5:
                return "üü°"
            else:
                return "üî¥"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        metrics_text = "‚úÖ Evaluation –∑–∞–≤–µ—Ä—à–µ–Ω!\n\n"
        metrics_text += f"üìä –î–∞—Ç–∞—Å–µ—Ç: {dataset_name}\n"
        metrics_text += f"üìù –ü—Ä–∏–º–µ—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {examples_count}\n\n"
        metrics_text += "üéØ RAGAS –ú–µ—Ç—Ä–∏–∫–∏:\n"
        
        for metric_name, metric_value in metrics.items():
            # –ü–æ–ª—É—á–∞–µ–º —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ü–≤–µ—Ç
            if metric_name in metric_translations:
                russian_name, _ = metric_translations[metric_name]
                emoji = get_metric_emoji(metric_name, metric_value)
            else:
                # –ï—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ –Ω–µ –≤ —Å–ª–æ–≤–∞—Ä–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                russian_name = metric_name.replace("_", " ").title()
                emoji = get_metric_emoji(metric_name, metric_value)
            
            # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 3 –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
            metric_value_str = f"{metric_value:.3f}"
            metrics_text += f"{emoji} {russian_name}: {metric_value_str}\n"

        metrics_text += "\nüí° –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ LangSmith –∫–∞–∫ feedback"

        await message.answer(metrics_text)
        logger.info("Evaluation –∑–∞–≤–µ—Ä—à—ë–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s. –ú–µ—Ç—Ä–∏–∫–∏: %s", user_id, metrics)

    except ValueError as exc:
        error_msg = str(exc)
        logger.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ evaluation –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, error_msg)
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {error_msg}")
    except Exception as exc:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ evaluation –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, exc)
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ evaluation. "
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        )


def _format_sources(documents: List[Document]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: 'üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: filename.pdf (—Å—Ç—Ä. 1, 3, 5)'."""
    if not documents:
        return "üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É –∏ —Å–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    source_pages: dict[str, set[int]] = {}
    for doc in documents:
        source = doc.metadata.get("source") or "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏
        filename = source.split("/")[-1] if "/" in source else source
        filename = filename.split("\\")[-1] if "\\" in filename else filename

        page = doc.metadata.get("page")
        if page is not None:
            if filename not in source_pages:
                source_pages[filename] = set()
            source_pages[filename].add(page)

    if not source_pages:
        return "üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    sources_list = []
    for filename, pages in sorted(source_pages.items()):
        pages_str = ", ".join(map(str, sorted(pages)))
        sources_list.append(f"{filename} (—Å—Ç—Ä. {pages_str})")

    return f"üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(sources_list)}"


@router.message()
async def handle_text_message(message: types.Message) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_id = message.from_user.id if message.from_user else -1
    if not message.text:
        logger.info("–ü–æ–ª—É—á–µ–Ω–æ –Ω–µ—Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç %s. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º.", user_id)
        return

    logger.info("–ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç %s. –î–ª–∏–Ω–∞: %s", user_id, len(message.text))
    manager = get_vector_store_manager()
    status = manager.status

    if status.chunks == 0:
        logger.info("–û—Ç–≤–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω: –∏–Ω–¥–µ–∫—Å –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –≥–æ—Ç–æ–≤.")
        await message.answer(
            "–ò–Ω–¥–µ–∫—Å –ø–æ–∫–∞ –ø—É—Å—Ç. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /index –∏ –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –∑–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–æ–ø—Ä–æ—Å."
        )
        return

    await message.bot.send_chat_action(chat_id=message.chat.id, action="typing")

    chat_history: List[BaseMessage] = session_manager.get_messages(user_id)
    retriever = manager.get_retriever()
    rag_chain = build_rag_chain(retriever)

    try:
        result = await rag_chain.ainvoke({"input": message.text, "chat_history": chat_history})
        answer: str = result.get("answer", "").strip()
        documents: List[Document] = result.get("context", [])

        if not answer:
            answer = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ."

        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ SHOW_SOURCES=true
        response_text = answer
        if config.SHOW_SOURCES:
            sources = _format_sources(documents)
            response_text = f"{answer}\n\n{sources}"

        session_manager.add_user_message(user_id, message.text)
        session_manager.add_ai_message(user_id, answer)

        logger.info("–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é %s –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω. –ß–∞–Ω–∫–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ: %s", user_id, len(documents))
        await message.answer(response_text)

    except BadRequestError as exc:
        logger.warning(
            "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, exc
        )
        await message.answer(
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏."
        )
    except Exception as exc:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ RAG-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %s: %s", user_id, exc)
        await message.answer("–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
