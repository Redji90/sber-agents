# Решение проблем с Rate Limiting от Groq API

## Проблема

Groq API имеет строгие rate limits:
- **6000 TPM** (tokens per minute) для бесплатного tier
- При превышении лимита возвращается ошибка **429 Too Many Requests**
- При частых запросах evaluation может занимать очень много времени из-за retry

## Реализованные оптимизации

### 1. Уменьшен параллелизм
- **EVALUATION_MAX_CONCURRENT**: изменено с `2` на `1` (последовательная обработка)
- Это гарантирует, что одновременно выполняется только один запрос к API

### 2. Увеличена задержка между запросами
- **EVALUATION_DELAY_BETWEEN_REQUESTS**: изменено с `1.0` на `2.0` секунд
- Задержка применяется после каждого успешного запроса

### 3. Улучшена обработка retry
- **max_retries** в `_process_single_example`: увеличено с `5` на `10`
- **Базовая задержка при retry**: увеличена с `5.0` на `10.0` секунд
- Экспоненциальная задержка: 10, 20, 40, 80 секунд

### 4. Увеличены timeout и retry в LLM клиентах
- **ChatOpenAI для RAGAS**: `max_retries=30`, `timeout=180.0`
- **AsyncOpenAI для основного LLM**: `max_retries=30`, `timeout=180.0`

## Настройка через переменные окружения

Вы можете переопределить настройки в `.env` файле:

```env
# Последовательная обработка (рекомендуется для Groq)
EVALUATION_MAX_CONCURRENT=1

# Задержка между запросами (секунды)
EVALUATION_DELAY_BETWEEN_REQUESTS=2.0
```

## Альтернативные решения

### Вариант 1: Увеличить задержку еще больше
Если проблемы с rate limiting продолжаются, увеличьте задержку:

```env
EVALUATION_DELAY_BETWEEN_REQUESTS=3.0  # или даже 5.0
```

### Вариант 2: Использовать другой LLM провайдер
Если Groq API слишком ограничивает, рассмотрите альтернативы:
- **OpenRouter** (более мягкие лимиты)
- **Together AI** (бесплатный tier)
- **DeepInfra** (бесплатный tier)

### Вариант 3: Использовать Groq Pro
Если нужна более высокая производительность, можно перейти на платный tier Groq Pro.

## Мониторинг

Во время evaluation следите за логами:
- Ошибки `429 Too Many Requests` должны быть редкими
- Если их много, увеличьте `EVALUATION_DELAY_BETWEEN_REQUESTS`
- `TimeoutError` может указывать на слишком агрессивные retry - уменьшите `max_retries` или увеличьте `timeout`

## Ожидаемое время выполнения

С текущими настройками (max_concurrent=1, delay=2.0):
- Для датасета из 8 примеров: ~2-3 минуты
- Для датасета из 50 примеров: ~15-20 минут
- Для датасета из 100 примеров: ~30-40 минут

Это медленнее, но надежнее и без ошибок rate limiting.

