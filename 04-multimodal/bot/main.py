"""Main bot application."""
import asyncio
import logging
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode

from bot.config import config
from bot.llm_client import LLMClient, VLMClient
from bot.storage import Storage
from bot.models import Transaction

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

bot = Bot(token=config.telegram_bot_token, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

storage = Storage(config.storage_path)
llm_client = LLMClient()
vlm_client = VLMClient()


async def safe_edit_text(message, text: str, max_retries: int = 2):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ —Å–µ—Ç–∏."""
    from aiogram.exceptions import TelegramNetworkError
    
    for attempt in range(max_retries):
        try:
            await message.edit_text(text)
            return True
        except TelegramNetworkError as e:
            logger.warning(f"Network error editing message (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(1)  # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
            else:
                logger.error(f"Failed to edit message after {max_retries} attempts")
                # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º bot –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–æ—Ç –∂–µ —á–∞—Ç
                    await bot.send_message(message.chat.id, text)
                    return True
                except Exception as send_error:
                    logger.error(f"Failed to send new message: {send_error}")
                    return False
        except Exception as e:
            logger.error(f"Unexpected error editing message: {e}")
            return False
    return False


@dp.message(Command("start"))
async def cmd_start(message: Message):
    """Start command handler."""
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π —Å–æ–≤–µ—Ç–Ω–∏–∫.\n\n"
        "–Ø –º–æ–≥—É:\n"
        "‚Ä¢ –ó–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ç–≤–æ–∏ –¥–æ—Ö–æ–¥—ã –∏ —Ä–∞—Å—Ö–æ–¥—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π\n"
        "‚Ä¢ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
        "‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —á–µ–∫–æ–≤\n"
        "‚Ä¢ –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –±–∞–ª–∞–Ω—Å (/balance)\n\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏!"
    )


@dp.message(Command("balance"))
async def cmd_balance(message: Message):
    """Show balance command handler."""
    balance = storage.get_balance()
    transactions = storage.get_transactions()
    
    income = sum(t.amount for t in transactions if t.type.value == "income")
    expense = sum(t.amount for t in transactions if t.type.value == "expense")
    
    response = (
        f"üí∞ <b>–¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å:</b> {balance:,.2f} ‚ÇΩ\n\n"
        f"üìà –î–æ—Ö–æ–¥—ã: {income:,.2f} ‚ÇΩ\n"
        f"üìâ –†–∞—Å—Ö–æ–¥—ã: {expense:,.2f} ‚ÇΩ\n"
        f"üìä –í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(transactions)}"
    )
    await message.answer(response)


@dp.message(F.voice | F.audio)
async def handle_voice(message: Message):
    """Handle voice messages."""
    status_msg = await message.answer("üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
    
    try:
        # Download voice file
        file_id = message.voice.file_id if message.voice else message.audio.file_id
        file = await bot.get_file(file_id)
        file_path = file.file_path
        
        # Download to local temp file
        import tempfile
        import os
        with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as tmp:
            await bot.download_file(file_path, tmp.name)
            temp_path = tmp.name
        
        try:
            # Transcribe audio
            await safe_edit_text(status_msg, "üîä –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å...")
            transcript = await transcribe_audio(temp_path)
            
            if transcript:
                logger.info(f"Transcription result: {transcript}")
                await safe_edit_text(status_msg, f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcript}\n\nüìù –ò–∑–≤–ª–µ–∫–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏...")
                
                # Extract transaction from transcript
                transaction = await llm_client.extract_transaction(transcript)
                if transaction:
                    storage.add_transaction(transaction)
                    await safe_edit_text(
                        status_msg,
                        f"‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞:\n"
                        f"üìÖ {transaction.date} {transaction.time}\n"
                        f"{'üí∞ –î–æ—Ö–æ–¥' if transaction.type.value == 'income' else 'üí∏ –†–∞—Å—Ö–æ–¥'}: {transaction.amount:,.2f} ‚ÇΩ\n"
                        f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {transaction.category.value}\n"
                        f"üìù {transaction.description}"
                    )
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM
                    error_hint = ""
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∏—á–∏–Ω—É –ø–æ –ª–æ–≥–∞–º (—ç—Ç–æ –±—É–¥–µ—Ç –≤–∏–¥–Ω–æ –≤ –ª–æ–≥–∞—Ö)
                    # –ù–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–∞–¥–∏–º –æ–±—â–∏–π —Å–æ–≤–µ—Ç
                    error_hint = (
                        "\n\nüí° <b>–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:</b>\n"
                        "‚Ä¢ –°–µ—Ä–≤–µ—Ä LLM (Ollama) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç\n"
                        "‚Ä¢ –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏\n"
                        "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–∫–∞–∑–∞—Ç—å —Å—É–º–º—É, —Ç–∏–ø (–¥–æ—Ö–æ–¥/—Ä–∞—Å—Ö–æ–¥) –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –±–æ–ª–µ–µ —è–≤–Ω–æ\n\n"
                        "–ü—Ä–∏–º–µ—Ä—ã:\n"
                        "‚Ä¢ \"–∫—É–ø–∏–ª –ø—Ä–æ–¥—É–∫—Ç—ã –Ω–∞ 500 —Ä—É–±–ª–µ–π\"\n"
                        "‚Ä¢ \"–ø–æ–ª—É—á–∏–ª –∑–∞—Ä–ø–ª–∞—Ç—É 50000\"\n"
                        "‚Ä¢ \"–ø–æ—Ç—Ä–∞—Ç–∏–ª 300 –Ω–∞ —Ç–∞–∫—Å–∏\""
                    )
                    
                    await safe_edit_text(
                        status_msg,
                        f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcript}\n\n"
                        "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è."
                        + error_hint
                    )
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                provider_hint = ""
                if config.speech_provider == "openai":
                    base_url = config.speech_base_url or config.llm_base_url or ""
                    if "ollama" in base_url.lower() or "11434" in base_url:
                        provider_hint = (
                            "\n\nüí° <b>–°–æ–≤–µ—Ç:</b> –ü–æ—Ö–æ–∂–µ, —á—Ç–æ Ollama –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Whisper API –¥–æ–ª–∂–Ω—ã–º –æ–±—Ä–∞–∑–æ–º.\n"
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n"
                            "‚Ä¢ <b>Vosk</b> (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –æ—Ñ–ª–∞–π–Ω) - —Å–º. VOSK_SETUP.md\n"
                            "‚Ä¢ <b>Yandex SpeechKit</b> (–ø–ª–∞—Ç–Ω–æ) - —Å–º. SPEECHKIT_SETUP.md"
                        )
                    else:
                        provider_hint = (
                            "\n\nüí° <b>–°–æ–≤–µ—Ç:</b> –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ OpenAI API.\n"
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                            "‚Ä¢ <b>Vosk</b> (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –æ—Ñ–ª–∞–π–Ω) - —Å–º. VOSK_SETUP.md\n"
                            "‚Ä¢ <b>Yandex SpeechKit</b> - —Å–º. SPEECHKIT_SETUP.md"
                        )
                elif config.speech_provider == "vosk":
                    provider_hint = (
                        "\n\nüí° <b>–°–æ–≤–µ—Ç:</b> –ü—Ä–æ–±–ª–µ–º—ã —Å Vosk.\n"
                        "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n"
                        "‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ (model_path)\n"
                        "‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ FFmpeg\n"
                        "‚Ä¢ –°–º. –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é: VOSK_SETUP.md"
                    )
                
                await safe_edit_text(
                    status_msg,
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.\n\n"
                    "–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                    "‚Ä¢ –ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ\n"
                    "‚Ä¢ –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏\n"
                    "‚Ä¢ –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ —Å–µ—Ä–≤–∏—Å—É"
                    + provider_hint
                )
        finally:
            os.unlink(temp_path)
    except ValueError as e:
        # Configuration errors
        error_msg = str(e)
        logger.error(f"Configuration error: {error_msg}")
        await safe_edit_text(
            status_msg,
            f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n{error_msg}\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≤ config.yaml –∏–ª–∏ .env —Ñ–∞–π–ª–µ.\n"
            "–°–º. –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é: SPEECHKIT_SETUP.md"
        )
    except Exception as e:
        logger.error(f"Error processing voice: {e}", exc_info=True)
        error_text = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è:\n{str(e)}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π."
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–æ–≤–æ–µ
        if not await safe_edit_text(status_msg, error_text):
            try:
                await message.answer(error_text)
            except Exception as send_error:
                logger.error(f"Failed to send error message to user: {send_error}")


async def transcribe_audio(audio_path: str) -> str:
    """Transcribe audio using configured provider (Yandex SpeechKit, OpenAI Whisper, Vosk, etc.)."""
    try:
        if config.speech_provider == "yandex":
            return await transcribe_yandex(audio_path)
        elif config.speech_provider == "openai":
            return await transcribe_openai(audio_path)
        elif config.speech_provider == "vosk":
            return await transcribe_vosk(audio_path)
        else:
            # Fallback to OpenAI if provider not specified
            logger.warning(f"Unknown speech provider: {config.speech_provider}, using OpenAI")
            return await transcribe_openai(audio_path)
    except Exception as e:
        logger.error(f"Transcription error: {e}", exc_info=True)
        return None


async def transcribe_yandex(audio_path: str) -> str:
    """Transcribe audio using Yandex SpeechKit."""
    import requests
    
    if not config.speech_api_key:
        raise ValueError("Yandex SpeechKit requires API key. Please configure in config.yaml or .env")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ—á–∏—â–∞–µ–º API-–∫–ª—é—á –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤
    api_key = config.speech_api_key.strip()
    if not api_key:
        raise ValueError("API key is empty after trimming whitespace")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –∫–ª—é—á–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
    logger.info(f"Using API key: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '****'} (length: {len(api_key)})")
    
    url = "https://stt.api.cloud.yandex.net/speech/v1/stt:recognize"
    
    headers = {
        "Authorization": f"Api-Key {api_key}",
    }
    
    # –ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ –ù–ï —É–∫–∞–∑—ã–≤–∞–µ–º folderId –≤ –∑–∞–ø—Ä–æ—Å–µ
    # SpeechKit –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–∞—Ç–∞–ª–æ–≥, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—ã–ª —Å–æ–∑–¥–∞–Ω —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç
    params = {
        "lang": config.speech_language,
        "format": "oggopus",  # Telegram voice messages are in OGG Opus format
    }
    
    # –ï—Å–ª–∏ folderId —É–∫–∞–∑–∞–Ω, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—ç—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É 401)
    # –£–¥–∞–ª—è–µ–º —ç—Ç—É —Å—Ç—Ä–æ–∫—É, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ folderId –Ω–µ –Ω—É–∂–µ–Ω
    
    with open(audio_path, "rb") as audio_file:
        response = requests.post(url, headers=headers, params=params, data=audio_file, timeout=30)
    
    if response.status_code != 200:
        error_msg = response.text
        logger.error(f"Yandex SpeechKit error: {response.status_code} - {error_msg}")
        
        # Provide helpful error messages
        if response.status_code == 401:
            error_detail = ""
            try:
                error_json = response.json()
                error_code = error_json.get("error_code", "")
                error_message = error_json.get("error_message", "")
                if "PermissionDenied" in error_message or error_code == "UNAUTHORIZED":
                    error_detail = (
                        "\n\n–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                        "‚Ä¢ API-–∫–ª—é—á —Å–æ–∑–¥–∞–Ω –Ω–µ –¥–ª—è —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ —Å —Ä–æ–ª—å—é ai.speechkit-stt.user\n"
                        "‚Ä¢ –†–æ–ª—å ai.speechkit-stt.user –Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –Ω–∞ –∫–∞—Ç–∞–ª–æ–≥ (folder)\n"
                        "‚Ä¢ Folder ID —É–∫–∞–∑–∞–Ω –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ\n"
                        "‚Ä¢ API-–∫–ª—é—á —É—Å—Ç–∞—Ä–µ–ª –∏–ª–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω\n\n"
                        "–°–º. –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é: SPEECHKIT_SETUP.md (—Ä–∞–∑–¥–µ–ª '–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º')"
                    )
            except:
                pass
            raise Exception(f"Yandex SpeechKit API error: 401 (Unauthorized){error_detail}")
        elif response.status_code == 403:
            raise Exception(
                f"Yandex SpeechKit API error: 403 (Forbidden)\n\n"
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç –∏–º–µ–µ—Ç —Ä–æ–ª—å ai.speechkit-stt.user "
                "–∏ —á—Ç–æ Folder ID —É–∫–∞–∑–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ.\n"
                "–°–º. –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é: SPEECHKIT_SETUP.md"
            )
        else:
            raise Exception(f"Yandex SpeechKit API error: {response.status_code} - {error_msg}")
    
    result = response.json()
    
    if "result" in result:
        return result["result"]
    else:
        error_msg = result.get("error_message", "Unknown error")
        logger.error(f"Yandex SpeechKit recognition error: {error_msg}")
        raise Exception(f"Recognition error: {error_msg}")


async def transcribe_openai(audio_path: str) -> str:
    """Transcribe audio using OpenAI Whisper API (or compatible API like Ollama)."""
    from openai import OpenAI as OpenAIClient
    import os
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ speech —Å–µ–∫—Ü–∏–∏, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã, –∏–Ω–∞—á–µ –∏–∑ llm —Å–µ–∫—Ü–∏–∏
    api_key = config.speech_api_key or config.llm_api_key or "dummy"
    base_url = config.speech_base_url or config.llm_base_url or "https://api.openai.com/v1"
    
    # Get file size for logging
    file_size = os.path.getsize(audio_path)
    logger.info(f"Using OpenAI Whisper API: base_url={base_url}, language={config.speech_language}, file_size={file_size} bytes")
    
    # Create client with increased timeout
    # Note: We handle retries manually, so set max_retries to 0 to avoid double retries
    transcription_client = OpenAIClient(
        api_key=api_key,
        base_url=base_url,
        timeout=120.0,  # 2 minutes timeout for large files
        max_retries=0,  # We handle retries manually in the loop below
    )
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    language = None
    if config.speech_language and config.speech_language != "auto":
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ru-RU –≤ ru, en-US –≤ en –∏ —Ç.–¥.
        lang_code = config.speech_language.split("-")[0] if "-" in config.speech_language else config.speech_language
        language = lang_code if lang_code != "auto" else None
    
    # Retry logic with exponential backoff
    max_attempts = 3
    for attempt in range(max_attempts):
        try:
            with open(audio_path, "rb") as audio_file:
                transcription_params = {
                    "model": "whisper-1",
                    "file": audio_file,
                }
                if language:
                    transcription_params["language"] = language
                
                logger.info(f"Transcription attempt {attempt + 1}/{max_attempts}")
                response = transcription_client.audio.transcriptions.create(**transcription_params)
                
                return response.text
                
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            logger.warning(f"Transcription attempt {attempt + 1} failed: {error_type}: {error_msg}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤—Ä—è–¥ –ª–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—Å—è
            is_connection_error = (
                "Connection error" in error_msg or 
                "disconnected" in error_msg.lower() or
                "RemoteProtocolError" in error_type
            )
            
            # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
            # –ù–æ –µ—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å–µ—Ä–≤–µ—Ä–∞ (disconnected), –Ω–µ —Ç—Ä–∞—Ç–∏–º –≤—Ä–µ–º—è –Ω–∞ –æ–∂–∏–¥–∞–Ω–∏–µ
            if is_connection_error and attempt < max_attempts - 1:
                # –î–ª—è –æ—à–∏–±–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥–µ–ª–∞–µ–º –∫–æ—Ä–æ—Ç–∫—É—é –ø–∞—É–∑—É
                wait_time = 0.5  # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –¥–ª—è –æ—à–∏–±–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                logger.info(f"Connection error detected, retrying in {wait_time} seconds...")
                await asyncio.sleep(wait_time)
            elif attempt < max_attempts - 1:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É
                wait_time = (2 ** attempt) * 1.0  # 1s, 2s, 4s
                logger.info(f"Retrying in {wait_time} seconds...")
                await asyncio.sleep(wait_time)
            else:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É
                logger.error(f"All {max_attempts} transcription attempts failed. Last error: {error_type}: {error_msg}")
                raise
    
    # Should not reach here, but just in case
    raise Exception("Transcription failed after all retry attempts")


async def transcribe_vosk(audio_path: str) -> str:
    """Transcribe audio using Vosk (offline speech recognition)."""
    import os
    import tempfile
    import json
    from vosk import Model, SetLogLevel, KaldiRecognizer
    from pydub import AudioSegment
    import wave
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
    if not config.speech_model_path:
        raise ValueError(
            "Vosk requires model_path. Please configure in config.yaml:\n"
            "speech:\n"
            "  provider: \"vosk\"\n"
            "  model_path: \"path/to/vosk-model\"\n\n"
            "Download models from: https://alphacephei.com/vosk/models"
        )
    
    model_path = config.speech_model_path
    if not os.path.exists(model_path):
        raise ValueError(
            f"Vosk model not found at path: {model_path}\n\n"
            "Please download a model from https://alphacephei.com/vosk/models\n"
            "Recommended for Russian: vosk-model-small-ru-0.22 or vosk-model-ru-0.42"
        )
    
    logger.info(f"Using Vosk model: {model_path}")
    
    # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ Vosk (–æ–Ω–∏ —Å–ª–∏—à–∫–æ–º –ø–æ–¥—Ä–æ–±–Ω—ã–µ)
    SetLogLevel(-1)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–∫—ç—à–∏—Ä—É–µ–º –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
    if not hasattr(transcribe_vosk, '_model_cache'):
        transcribe_vosk._model_cache = {}
    
    if model_path not in transcribe_vosk._model_cache:
        logger.info(f"Loading Vosk model from {model_path}...")
        transcribe_vosk._model_cache[model_path] = Model(model_path)
        logger.info("Vosk model loaded successfully")
    
    model = transcribe_vosk._model_cache[model_path]
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç Vosk (WAV, 16kHz, mono, PCM)
    # Vosk —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º executor –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    def convert_and_transcribe():
        wav_path = None
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ WAV
            audio = AudioSegment.from_file(audio_path)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ, 16kHz, PCM (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è Vosk)
            audio = audio.set_channels(1)  # –ú–æ–Ω–æ
            audio = audio.set_frame_rate(16000)  # 16kHz
            audio = audio.set_sample_width(2)  # 16-bit PCM
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
                audio.export(tmp_wav.name, format="wav")
                wav_path = tmp_wav.name
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º WAV —Ñ–∞–π–ª —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º context manager –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
            with wave.open(wav_path, "rb") as wf:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç
                if wf.getnchannels() != 1:
                    raise ValueError("Audio file must be mono")
                if wf.getcomptype() != "NONE":
                    raise ValueError("Audio file must be uncompressed PCM")
                
                # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º API
                rec = KaldiRecognizer(model, wf.getframerate())
                rec.SetWords(True)  # –í–∫–ª—é—á–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å–ª–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                
                # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º –∞—É–¥–∏–æ
                results = []
                while True:
                    data = wf.readframes(4000)  # –ß–∏—Ç–∞–µ–º –ø–æ 4000 —Ñ—Ä–µ–π–º–æ–≤
                    if len(data) == 0:
                        break
                    if rec.AcceptWaveform(data):
                        result = json.loads(rec.Result())
                        if result.get("text"):
                            results.append(result["text"])
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                final_result = json.loads(rec.FinalResult())
                if final_result.get("text"):
                    results.append(final_result["text"])
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            text = " ".join(results).strip()
            
            if not text:
                raise Exception("Vosk recognition returned empty result")
            
            return text
            
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV —Ñ–∞–π–ª –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è
            if wav_path and os.path.exists(wav_path):
                try:
                    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Windows, —á—Ç–æ–±—ã —Ñ–∞–π–ª —Ç–æ—á–Ω–æ –±—ã–ª –∑–∞–∫—Ä—ã—Ç
                    import time
                    time.sleep(0.1)
                    os.unlink(wav_path)
                except (PermissionError, OSError) as e:
                    logger.warning(f"Could not delete temporary file {wav_path}: {e}")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (Vosk —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π)
    loop = asyncio.get_event_loop()
    text = await loop.run_in_executor(None, convert_and_transcribe)
    
    logger.info(f"Vosk transcription result: {text}")
    return text


@dp.message(F.photo)
async def handle_photo(message: Message):
    """Handle photo messages (receipts)."""
    status_msg = await message.answer("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–∫–∞...")
    
    try:
        # Get largest photo
        photo = message.photo[-1]
        file = await bot.get_file(photo.file_id)
        
        # Download image to temp file
        import tempfile
        import os
        import base64
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
            await bot.download_file(file.file_path, tmp.name)
            temp_path = tmp.name
        
        try:
            # For Ollama, we need base64 or local file
            if config.vlm_provider == "ollama":
                # Optimize image size for Ollama (resize if too large)
                from PIL import Image
                import io
                
                # Open and resize if needed
                img = Image.open(temp_path)
                # Convert to RGB if needed
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Resize if image is too large (max 1024px on longest side)
                max_size = 1024
                if max(img.size) > max_size:
                    ratio = max_size / max(img.size)
                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
                    img = img.resize(new_size, Image.Resampling.LANCZOS)
                    logger.info(f"Resized image from {img.size} to {new_size}")
                
                # Save to bytes and encode
                img_bytes = io.BytesIO()
                img.save(img_bytes, format='JPEG', quality=85, optimize=True)
                image_base64 = base64.b64encode(img_bytes.getvalue()).decode("utf-8")
                logger.info(f"Image encoded, base64 size: {len(image_base64)} chars")
                
                transaction = await vlm_client.extract_transaction_from_image(image_base64=image_base64)
            else:
                # For OpenRouter/OpenAI, use URL
                file_url = f"https://api.telegram.org/file/bot{config.telegram_bot_token}/{file.file_path}"
                transaction = await vlm_client.extract_transaction_from_image(image_url=file_url)
        finally:
            os.unlink(temp_path)
        
        if transaction:
            storage.add_transaction(transaction)
            await safe_edit_text(
                status_msg,
                f"‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –∏–∑ —á–µ–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞:\n"
                f"üìÖ {transaction.date} {transaction.time}\n"
                f"{'üí∞ –î–æ—Ö–æ–¥' if transaction.type.value == 'income' else 'üí∏ –†–∞—Å—Ö–æ–¥'}: {transaction.amount:,.2f} ‚ÇΩ\n"
                f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {transaction.category.value}\n"
                f"üìù {transaction.description}"
            )
        else:
            await safe_edit_text(status_msg, "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
    except Exception as e:
        logger.error(f"Error processing photo: {e}", exc_info=True)
        error_text = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"
        if not await safe_edit_text(status_msg, error_text):
            try:
                await message.answer(error_text)
            except Exception as send_error:
                logger.error(f"Failed to send error message to user: {send_error}")


@dp.message(F.text & ~F.text.startswith("/"))
async def handle_text(message: Message):
    """Handle text messages."""
    text = message.text
    
    # Extract transaction from text
    transaction = await llm_client.extract_transaction(text)
    
    if transaction:
        storage.add_transaction(transaction)
        await message.answer(
            f"‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞:\n"
            f"üìÖ {transaction.date} {transaction.time}\n"
            f"{'üí∞ –î–æ—Ö–æ–¥' if transaction.type.value == 'income' else 'üí∏ –†–∞—Å—Ö–æ–¥'}: {transaction.amount:,.2f} ‚ÇΩ\n"
            f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {transaction.category.value}\n"
            f"üìù {transaction.description}"
        )
    else:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.\n"
            "–ü–æ–ø—Ä–æ–±—É–π –æ–ø–∏—Å–∞—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n"
            "‚Ä¢ '–ö—É–ø–∏–ª –ø—Ä–æ–¥—É–∫—Ç—ã –Ω–∞ 500 —Ä—É–±–ª–µ–π –≤ –º–∞–≥–∞–∑–∏–Ω–µ'\n"
            "‚Ä¢ '–ü–æ–ª—É—á–∏–ª –∑–∞—Ä–ø–ª–∞—Ç—É 50000 —Ä—É–±–ª–µ–π'\n"
            "‚Ä¢ '–ó–∞–∫–∞–∑–∞–ª —Ç–∞–∫—Å–∏ –Ω–∞ 300 —Ä—É–±–ª–µ–π'"
        )


async def main():
    """Main entry point."""
    logger.info("Starting bot...")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())

