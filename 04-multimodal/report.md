# Отчёт о выполнении задания

## Название проекта

**Финансовый советник Telegram-бот** — LLM-based мультимодальный бот для учета личных доходов и расходов с поддержкой обработки текстовых сообщений, голосовых сообщений и изображений чеков.

## Вариант задания

**Расширенный вариант** — реализована полная мультимодальность:
- ✅ Обработка текстовых сообщений
- ✅ Обработка голосовых сообщений с транскрипцией
- ✅ Обработка изображений чеков (Vision Language Model)

## Реализованные возможности

### Основной функционал
- ✅ Ведение учета транзакций (дата, время, тип, сумма, категория, описание, частота)
- ✅ Автоматическое извлечение данных из текстовых сообщений с использованием LLM
- ✅ Обработка голосовых сообщений с транскрипцией речи в текст
- ✅ Обработка изображений чеков с использованием Vision Language Model (VLM)
- ✅ Отчет о балансе по команде `/balance`
- ✅ Хранение транзакций в JSON формате

### Дополнительные возможности
- ✅ Поддержка множественных провайдеров для распознавания речи (OpenAI Whisper API, Yandex SpeechKit, Vosk)
- ✅ Поддержка множественных провайдеров для LLM/VLM (OpenRouter, Ollama)
- ✅ Обработка ошибок сети с автоматическими повторами и экспоненциальной задержкой
- ✅ Безопасное редактирование сообщений с fallback на отправку нового сообщения
- ✅ Детальное логирование для отладки
- ✅ Гибкая конфигурация через YAML и переменные окружения
- ✅ Поддержка структурированного вывода (JSON schema) для извлечения транзакций

## Технологический стек

### Язык программирования и инструменты
- **Python 3.11+** — основной язык разработки
- **uv** — современный менеджер пакетов и зависимостей для Python
- **aiogram 3.0+** — асинхронный фреймворк для Telegram Bot API
- **openai 1.0+** — клиент для работы с OpenAI-совместимыми API (Ollama, OpenRouter)

### Библиотеки для обработки данных
- **pyyaml** — работа с YAML конфигурацией
- **python-dotenv** — загрузка переменных окружения
- **pillow** — обработка изображений (изменение размера, кодирование)
- **vosk** — офлайн распознавание речи
- **pydub** — конвертация аудио форматов (OGG → WAV)

### Модели машинного обучения

#### LLM (Language Model) — для извлечения транзакций из текста
- **llama3.2:1b** — легковесная модель для быстрой обработки текста
- **qwen2.5:7b-instruct** — более мощная модель для сложных случаев (установлена на сервере)

#### VLM (Vision Language Model) — для обработки изображений
- **llava:latest** — мультимодальная модель для анализа изображений и извлечения информации из чеков

#### STT (Speech-to-Text) — для распознавания речи
- **Vosk** (vosk-model-small-ru-0.22) — локальная модель для русского языка
- **OpenAI Whisper API** (через Ollama) — облачное решение
- **Yandex SpeechKit** — облачное решение от Яндекса

## Инструменты AI-driven разработки

### IDE и редакторы
- **Cursor** — AI-powered IDE с интеграцией LLM для автодополнения и рефакторинга
- **Git** — система контроля версий

### LLM модели, использованные в разработке
- **Claude (через Cursor)** — для генерации кода, рефакторинга, отладки и написания документации
- **GPT-4** (опционально) — для сложных архитектурных решений

### Применение AI в разработке
- Генерация кода обработчиков сообщений
- Рефакторинг и оптимизация существующего кода
- Написание документации и комментариев
- Отладка и исправление ошибок
- Генерация промптов для LLM
- Создание скриптов для автоматизации (SSH, настройка сервера)

## Скриншоты работы

> **Примечание:** Скриншоты работы бота находятся в папке `screenshots/`. Для демонстрации функционала рекомендуется добавить скриншоты:
> - Интерфейс бота в Telegram
> - Пример обработки текстового сообщения
> - Пример обработки голосового сообщения
> - Пример обработки изображения чека
> - Результат команды `/balance`

Примеры скриншотов (если добавлены):
- ![Обработка текста](screenshots/text_example.png)
- ![Обработка голоса](screenshots/voice_example.png)
- ![Обработка изображения](screenshots/image_example.png)
- ![Баланс](screenshots/balance_example.png)

## Облачный сервер

### Провайдер и конфигурация
- **Провайдер:** immers.cloud
- **IP адрес:** 195.209.210.171
- **ОС:** Ubuntu Linux
- **GPU:** Доступна (проверена через `nvidia-smi`)
- **Пользователь:** ubuntu

### Установленные модели Ollama

#### LLM модели
- **llama3.2:1b** (1.3 GB) — основная модель для обработки текста
- **qwen2.5:7b-instruct** (4.7 GB) — альтернативная модель для сложных случаев

#### VLM модели
- **llava:latest** (4.7 GB) — модель для обработки изображений и извлечения информации из чеков

### Настройка доступа
- **Ollama API:** доступен извне на порту `11434` (настроен через systemd override)
- **Firewall:** порты 22 (SSH) и 11434 (Ollama) открыты через `ufw`
- **Конфигурация:** `OLLAMA_HOST=0.0.0.0:11434` для прослушивания на всех интерфейсах

## Основные вызовы и решения

### 1. Проблема: Ошибки подключения к Ollama при транскрипции
**Вызов:** `openai.APIConnectionError: Connection error. Server disconnected without sending a response.`

**Решение:**
- Реализована система повторных попыток с экспоненциальной задержкой (1s, 2s, 4s)
- Увеличен timeout до 120 секунд для длительных операций
- Добавлен fallback на альтернативные провайдеры (Yandex SpeechKit, Vosk)

### 2. Проблема: Ошибки сети Telegram при редактировании сообщений
**Вызов:** `TelegramNetworkError: HTTP Client says - ClientConnectorError`

**Решение:**
- Создана функция `safe_edit_text()` с автоматическими повторами
- Реализован fallback: при неудачном редактировании отправляется новое сообщение
- Добавлена обработка всех типов сетевых ошибок Telegram API

### 3. Проблема: Неправильная работа Vosk на Windows
**Вызов:** 
- `AttributeError: 'Model' object has no attribute 'createRec'`
- `PermissionError: [WinError 32] The process cannot access the file`

**Решение:**
- Использован правильный API Vosk: `KaldiRecognizer(model, sample_rate)` вместо устаревшего `createRec()`
- Реализовано правильное закрытие файлов через context manager (`with wave.open()`)
- Добавлена задержка перед удалением временных файлов на Windows (`time.sleep(0.1)`)

### 4. Проблема: Ollama недоступен извне
**Вызов:** Ollama слушал только на `127.0.0.1:11434`, недоступен с внешних IP

**Решение:**
- Создан systemd override файл `/etc/systemd/system/ollama.service.d/override.conf`
- Установлена переменная окружения `OLLAMA_HOST=0.0.0.0:11434`
- Выполнены команды `systemctl daemon-reload` и `systemctl restart ollama`
- Проверена доступность через `curl` с внешнего IP

### 5. Проблема: LLM не извлекал транзакции из неидеального текста
**Вызов:** Модель возвращала `null` для текста с ошибками распознавания речи

**Решение:**
- Улучшен промпт с примерами и явными инструкциями для обработки неидеального текста
- Добавлены инструкции для вывода транзакций даже при частичной информации
- Реализовано логирование сырых ответов LLM для отладки
- Добавлена обработка различных форматов JSON ответов (с markdown code blocks и без)

### 6. Проблема: Отсутствие VLM модели на новом сервере
**Вызов:** `openai.NotFoundError: model 'llava:latest' not found`

**Решение:**
- Установлена модель через `ollama pull llava:latest` на удаленном сервере
- Проверена доступность через API `/v1/models`

### 7. Проблема: Конфликт нескольких экземпляров бота
**Вызов:** `TelegramConflictError: terminated by other getUpdates request`

**Решение:**
- Найдены и завершены все запущенные процессы Python через PowerShell
- Использована команда `Get-Process python | Stop-Process -Force`

## Что узнал нового

### 1. Работа с Vosk для офлайн распознавания речи
- Изучил API Vosk (`KaldiRecognizer`, `Model`, `SetLogLevel`)
- Научился конвертировать аудио форматы (OGG Opus → WAV 16kHz mono) с помощью `pydub`
- Понял важность правильного формата аудио для распознавания (16kHz, mono, PCM)
- Освоил кэширование моделей для оптимизации производительности

### 2. Настройка Ollama на удаленном сервере
- Изучил systemd override файлы для изменения конфигурации сервисов
- Научился настраивать Ollama для доступа извне (изменение `OLLAMA_HOST`)
- Освоил работу с `ufw` для управления firewall правилами
- Понял важность проверки доступности сервисов с внешних IP

### 3. Обработка ошибок в асинхронном коде
- Реализовал систему повторных попыток с экспоненциальной задержкой
- Научился обрабатывать различные типы сетевых ошибок (timeout, connection error, network error)
- Освоил fallback механизмы для повышения надежности приложения
- Понял важность правильного логирования для отладки асинхронных приложений

### 4. Работа с мультимодальными моделями
- Изучил различия между LLM и VLM моделями
- Научился кодировать изображения в base64 для передачи в VLM
- Освоил оптимизацию размера изображений для уменьшения нагрузки на API
- Понял важность правильных промптов для извлечения структурированных данных из изображений

### 5. AI-driven разработка с Cursor
- Научился эффективно использовать AI для генерации кода и рефакторинга
- Освоил работу с контекстом проекта для получения релевантных ответов
- Понял важность итеративного подхода: генерация → тестирование → улучшение
- Изучил лучшие практики промптов для получения качественного кода

---

**Дата создания отчёта:** 2024

**Статус проекта:** ✅ Завершён и готов к использованию

