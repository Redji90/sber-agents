# Отчёт о разработке RAG-бота «Sber Agents AIdd Bot»

## О проекте
- **Название:** Sber Agents AIdd Bot  
- **Описание:** Telegram-бот банковского ассистента, использующий Retrieval-Augmented Generation для ответов на вопросы клиентов по данным PDF и JSON-FAQ Сбербанка.
- **Вариант задания:** расширенный (интеграция PDF + JSON, эксперименты с индексированием, сравнение эмбеддингов).

## Реализованные возможности
- [x] Интеграция Telegram-бота на aiogram 3.x  
- [x] Переиндексация данных из `@data` (PDF + JSON) командами `/index` и при старте  
- [x] Хранение статуса индексации и команда `/index_status`  
- [x] Диалоговый RAG-пайплайн с историей сообщений (LangChain)  
- [x] Поддержка JSON FAQ через `JSONLoader` и объединение с PDF  
- [x] Эксперименты с разными размерами чанков и запись результатов  
- [x] Переключение эмбеддингов на локальные Ollama-модели  

## Технологический стек
- Python 3.11, aiogram 3.x  
- LangChain (chains, retrievers, JSONLoader), InMemoryVectorStore  
- Ollama (локальные эмбеддинги), Fireworks/OpenRouter (LLM)  
- OpenAI совместимый клиент (`langchain-openai`)  
- Управление зависимостями: `uv`, сборка `make`  

## Используемые модели
- **LLM:** `accounts/fireworks/models/llama-v3p1-8b-instruct` (Fireworks)  
- **Эмбеддинги:** 
  - Fireworks `accounts/fireworks/models/nomic-embed-text-v1` (на ранних этапах)  
  - Ollama `aroxima/multilingual-e5-large-instruct:latest` (текущая версия)  

---

## Эксперименты с индексацией
| Параметры (`chunk_size`, `chunk_overlap`) | Кол-во чанков | Наблюдения |
| --- | --- | --- |
| 1500 / 150 | 132 | Ответы компактные, но мало деталей; релевантность сохраняется |
| 800 / 100 + адаптивные `separators` | 246 | Ответы структурированнее, релевантность хорошая |
| 300 / 50 | 652 | Ответы теряют контекст и становятся нерелевантными |
| 1500 / 150 (финальный тест с JSON) | 353 (PDF) + 313 (JSON) | Связность хорошая, но требуется нормализация JSON |

**Вывод:** оптимально использовать «средний» размер 600–800 символов с адаптивными разделителями. Для банковских документов это даёт баланс между детализацией и полноценным контекстом. Слишком мелкие чанки сильно ухудшают ответы.

---

## Работа с JSON датасетом
- Использован `langchain_community.document_loaders.JSONLoader` с `jq_schema='.[].full_text'`.  
- При загрузке JSON:
  - Добавляются метаданные `source` и `document_type=json_qa`.  
  - Чистятся неразрывные пробелы (\xa0, \u202f) и чанк разделяется теми же правилами, что и PDF.  
- Комбинация PDF-чанков и JSON-чанков агрегируется перед векторизацией.

**Скриншот:**  
![Ответ на вопрос про карты](screenshots/how_to_order_card.png)

---

## Сравнение моделей эмбеддингов

| Модель | Источник | Результат |
| --- | --- | --- |
| `accounts/fireworks/models/nomic-embed-text-v1` | Fireworks (удалённый) | Работает, но требует API; чувствительна к качеству текста (закодированные пробелы) |
| `aroxima/multilingual-e5-large-instruct:latest` | Ollama (локально) | Бесплатно, устойчиво к русскому тексту, обеспечивает стабильные совпадения |

**Вывод:** для русского языка и локальной работы лучше использовать локальную модель через Ollama (`multilingual-e5`). Она не требует API ключей и точнее сопоставляет FAQ, особенно после нормализации текста.

---

## Итог
Проект реализован в расширенном варианте: бот полностю переиндексирует банковские PDF и JSON FAQ, поддерживает ряд экспериментов и локальные эмбеддинги. Идеальная стратегия: адаптивные чанки (~600–800 символов) + локальные эмбеддинги Ollama.

