## Идея: LLM-ассистент как Telegram-бот

### Цель
Создать RAG-ассистента в виде Telegram-бота: бот ведёт диалог с пользователем и отвечает на вопросы, сочетая собственную роль и знания из локальной базы PDF-документов.

### Ключевая функциональность
- Ведение диалога в чате Telegram.
- Ответы на вопросы пользователя с учётом роли и с использованием Retrieval-Augmented Generation (RAG).
- Хранение истории переписки в формате LangChain messages (HumanMessage, AIMessage, SystemMessage).
- Индексация PDF-файлов из директории `@data` в InMemory векторную базу.
- Команды `/index` и `/index_status` для управления процессом индексации и проверки статуса.

### Роль модели
- Роль задаётся в системном промпте LLM как «банковский ассистент».
- Ответ формируется на основе роли, истории диалога и релевантных чанков из PDF-документов.

### Базовые требования
- Платформа: Telegram-бот на базе `aiogram` (polling).
- Основная задача: вести диалог и отвечать на вопросы пользователя, используя роль и локальный контент.
- Архитектура должна позволять менять роль (через системный промпт) без переписывания остального кода.
- Индексация выполняется при старте бота и по команде `/index`.
- Векторная база хранится в памяти процесса (InMemoryVectorStore).

### MVP-рамки
- Команды: `/start`, `/help`, `/reset`, `/index`, `/index_status`, диалоговые сообщения.
- Переиндексация PDF-документов при старте и по команде `/index`.
- Хранение статуса индексации (количество чанков, текущий статус).
- Извлечение топ-K чанков (значение из конфигурации).
- Логи минимум уровня `INFO` для диагностики.

### Расширения (по мере надобности)
- Ротация/выгрузка индекса на диск.
- Альтернативные векторные хранилища.
- Дополнительные команды администратора и расширенные настройки.

